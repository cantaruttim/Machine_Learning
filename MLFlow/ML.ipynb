{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. mlflow server --host 127.0.0.1 --port 8080\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Load the Iris dataset\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the model hyperparameters\n",
    "params = {\n",
    "    \"solver\": \"lbfgs\",\n",
    "    \"max_iter\": 1000,\n",
    "    \"multi_class\": \"auto\",\n",
    "    \"random_state\": 8888,\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"MLflow Quickstart\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"Basic LR model for iris data\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, lr.predict(X_train))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=lr,\n",
    "        artifact_path=\"iris_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"tracking-quickstart\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model back for predictions as a generic Python Function model\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "iris_feature_names = datasets.load_iris().feature_names\n",
    "\n",
    "result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "\n",
    "result[:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_x = train.drop([\"quality\"], axis=1).values\n",
    "train_y = train[[\"quality\"]].values.ravel()\n",
    "test_x = test.drop([\"quality\"], axis=1).values\n",
    "test_y = test[[\"quality\"]].values.ravel()\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(\n",
    "    train_x, train_y, test_size=0.2, random_state=42\n",
    ")\n",
    "signature = infer_signature(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params, epochs, train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
    "    # Define model architecture\n",
    "    mean = np.mean(train_x, axis=0)\n",
    "    var = np.var(train_x, axis=0)\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean, variance=var),\n",
    "            keras.layers.Dense(64, activation=\"relu\"),\n",
    "            keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(\n",
    "            learning_rate=params[\"lr\"], momentum=params[\"momentum\"]\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    # Train model with MLflow tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(\n",
    "            train_x,\n",
    "            train_y,\n",
    "            validation_data=(valid_x, valid_y),\n",
    "            epochs=epochs,\n",
    "            batch_size=64,\n",
    "        )\n",
    "        # Evaluate the model\n",
    "        eval_result = model.evaluate(valid_x, valid_y, batch_size=64)\n",
    "        eval_rmse = eval_result[1]\n",
    "\n",
    "        # Log parameters and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\", eval_rmse)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.tensorflow.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "        return {\"loss\": eval_rmse, \"status\": STATUS_OK, \"model\": model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLflow will track the parameters and results for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y,\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", np.log(1e-5), np.log(1e-1)),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.0, 1.0),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/02 23:21:41 INFO mlflow.tracking.fluent: Experiment with name '/wine-quality' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m31s\u001b[0m 698ms/step - loss: 34.3123 - root_mean_squared_error: 5.8577\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.0641 - root_mean_squared_error: 2.5088 - val_loss: 0.5832 - val_root_mean_squared_error: 0.7636\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.5883 - root_mean_squared_error: 0.7670\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5881 - root_mean_squared_error: 0.7666 - val_loss: 0.5187 - val_root_mean_squared_error: 0.7202\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.7323 - root_mean_squared_error: 0.8557\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5256 - root_mean_squared_error: 0.7244 - val_loss: 0.5492 - val_root_mean_squared_error: 0.7411\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5170 - root_mean_squared_error: 0.7191\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5452 - root_mean_squared_error: 0.7382 \n",
      "\n",
      "  0%|          | 0/8 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/02 23:21:53 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run classy-fox-329 at: http://127.0.0.1:8080/#/experiments/477308564409235171/runs/4b99bc79974d4dc6a769362d4598e8f7.\n",
      "\n",
      "2024/10/02 23:21:53 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/477308564409235171.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m22s\u001b[0m 496ms/step - loss: 40.3450 - root_mean_squared_error: 6.3518\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 38.9961 - root_mean_squared_error: 6.2443 - val_loss: 35.8787 - val_root_mean_squared_error: 5.9899\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 35.8345 - root_mean_squared_error: 5.9862\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.3594 - root_mean_squared_error: 5.8614 - val_loss: 32.0145 - val_root_mean_squared_error: 5.6581\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 32.3662 - root_mean_squared_error: 5.6891\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.7383 - root_mean_squared_error: 5.5440 - val_loss: 28.5865 - val_root_mean_squared_error: 5.3466\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 28.7274 - root_mean_squared_error: 5.3598\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.2614 - root_mean_squared_error: 5.3161 \n",
      "\n",
      " 12%|â–ˆâ–        | 1/8 [00:12<01:21, 11.66s/trial, best loss: 0.7410722970962524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/02 23:22:01 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run rambunctious-fly-280 at: http://127.0.0.1:8080/#/experiments/477308564409235171/runs/226d5b6e147b4231bb76eeb13d76d6aa.\n",
      "\n",
      "2024/10/02 23:22:01 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/477308564409235171.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m19s\u001b[0m 441ms/step - loss: 33.5385 - root_mean_squared_error: 5.7912\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 14.0182 - root_mean_squared_error: 3.6259 - val_loss: 1.9625 - val_root_mean_squared_error: 1.4009\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 1.6285 - root_mean_squared_error: 1.2761\n",
      "\u001b[1m42/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6724 - root_mean_squared_error: 1.2929 \n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6601 - root_mean_squared_error: 1.2881 - val_loss: 1.4169 - val_root_mean_squared_error: 1.1903\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1.2985 - root_mean_squared_error: 1.1395\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1951 - root_mean_squared_error: 1.0931 - val_loss: 1.1612 - val_root_mean_squared_error: 1.0776\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.1013 - root_mean_squared_error: 1.0494\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2102 - root_mean_squared_error: 1.0997 \n",
      "\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:20<00:55,  9.25s/trial, best loss: 0.7410722970962524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/02 23:22:08 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run clumsy-shoat-285 at: http://127.0.0.1:8080/#/experiments/477308564409235171/runs/9c5463e56b184edb8801dd34cbb86769.\n",
      "\n",
      "2024/10/02 23:22:08 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/477308564409235171.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m20s\u001b[0m 450ms/step - loss: 33.2606 - root_mean_squared_error: 5.7672\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 33.2747 - root_mean_squared_error: 5.7684 - val_loss: 32.4537 - val_root_mean_squared_error: 5.6968\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 31.7282 - root_mean_squared_error: 5.6328\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.8895 - root_mean_squared_error: 5.6470 - val_loss: 31.3208 - val_root_mean_squared_error: 5.5965\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 31.9690 - root_mean_squared_error: 5.6541\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 31.0174 - root_mean_squared_error: 5.5693 - val_loss: 30.2292 - val_root_mean_squared_error: 5.4981\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 29.8067 - root_mean_squared_error: 5.4596\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30.0472 - root_mean_squared_error: 5.4815 \n",
      "\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:27<00:42,  8.55s/trial, best loss: 0.7410722970962524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/02 23:22:16 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run popular-lamb-927 at: http://127.0.0.1:8080/#/experiments/477308564409235171/runs/c0d2ec9744da4f228efe735dbb9d02f8.\n",
      "\n",
      "2024/10/02 23:22:16 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/477308564409235171.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m20s\u001b[0m 456ms/step - loss: 34.5451 - root_mean_squared_error: 5.8775\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.4748 - root_mean_squared_error: 2.1668 - val_loss: 0.9448 - val_root_mean_squared_error: 0.9720\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.8230 - root_mean_squared_error: 0.9072\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6801 - root_mean_squared_error: 0.8244 - val_loss: 0.5895 - val_root_mean_squared_error: 0.7678\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.6879 - root_mean_squared_error: 0.8294\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5889 - root_mean_squared_error: 0.7672 - val_loss: 0.5947 - val_root_mean_squared_error: 0.7712\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5433 - root_mean_squared_error: 0.7371\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5944 - root_mean_squared_error: 0.7708 \n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:35<00:32,  8.25s/trial, best loss: 0.7410722970962524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/02 23:22:24 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run lyrical-cub-770 at: http://127.0.0.1:8080/#/experiments/477308564409235171/runs/572da72e856842a99c02892b09903923.\n",
      "\n",
      "2024/10/02 23:22:24 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/477308564409235171.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m19s\u001b[0m 438ms/step - loss: 39.8761 - root_mean_squared_error: 6.3148\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.2050 - root_mean_squared_error: 2.4891 - val_loss: 0.9145 - val_root_mean_squared_error: 0.9563\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.0187 - root_mean_squared_error: 1.0093\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8211 - root_mean_squared_error: 0.9051 - val_loss: 0.6241 - val_root_mean_squared_error: 0.7900\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.5400 - root_mean_squared_error: 0.7349\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6253 - root_mean_squared_error: 0.7906 - val_loss: 0.5654 - val_root_mean_squared_error: 0.7519\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5132 - root_mean_squared_error: 0.7164\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5481 - root_mean_squared_error: 0.7401 \n",
      "\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5/8 [00:43<00:24,  8.11s/trial, best loss: 0.7410722970962524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/02 23:22:31 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run wise-slug-898 at: http://127.0.0.1:8080/#/experiments/477308564409235171/runs/2be83a6be4ac42a8ae3ea23ba6ffc3f8.\n",
      "\n",
      "2024/10/02 23:22:31 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/477308564409235171.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m19s\u001b[0m 434ms/step - loss: 32.9060 - root_mean_squared_error: 5.7364\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 31.1268 - root_mean_squared_error: 5.5780 - val_loss: 24.7313 - val_root_mean_squared_error: 4.9731\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 22.3108 - root_mean_squared_error: 4.7234\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.7692 - root_mean_squared_error: 4.7712 - val_loss: 18.2019 - val_root_mean_squared_error: 4.2664\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 16.6065 - root_mean_squared_error: 4.0751\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1743 - root_mean_squared_error: 4.1429 - val_loss: 13.3752 - val_root_mean_squared_error: 3.6572\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 13.3121 - root_mean_squared_error: 3.6486\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.3026 - root_mean_squared_error: 3.6472 \n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:50<00:15,  7.84s/trial, best loss: 0.7410722970962524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/02 23:22:40 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run righteous-sheep-748 at: http://127.0.0.1:8080/#/experiments/477308564409235171/runs/5c9860dccdd54eff805d3578e21b198e.\n",
      "\n",
      "2024/10/02 23:22:40 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/477308564409235171.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m21s\u001b[0m 479ms/step - loss: 28.5678 - root_mean_squared_error: 5.3449\n",
      "\u001b[1m17/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.4934 - root_mean_squared_error: 5.5216   \n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 30.6281 - root_mean_squared_error: 5.5341 - val_loss: 29.2294 - val_root_mean_squared_error: 5.4064\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 31.0661 - root_mean_squared_error: 5.5737\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.9188 - root_mean_squared_error: 5.3773 - val_loss: 27.1673 - val_root_mean_squared_error: 5.2122\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 25.9542 - root_mean_squared_error: 5.0945\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.7074 - root_mean_squared_error: 5.1678 - val_loss: 25.2586 - val_root_mean_squared_error: 5.0258\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24.9757 - root_mean_squared_error: 4.9976\n",
      "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25.0934 - root_mean_squared_error: 5.0093 \n",
      "\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:59<00:08,  8.01s/trial, best loss: 0.7410722970962524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/02 23:22:48 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run able-fawn-369 at: http://127.0.0.1:8080/#/experiments/477308564409235171/runs/74e8752dff1c490dbc0e65f82781dc08.\n",
      "\n",
      "2024/10/02 23:22:48 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/477308564409235171.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:06<00:00,  8.28s/trial, best loss: 0.7410722970962524]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/02 23:22:54 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run aged-toad-505 at: http://127.0.0.1:8080/#/experiments/477308564409235171/runs/dcf0f237709a48d581816193077c32a6.\n",
      "2024/10/02 23:22:54 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/477308564409235171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'lr': 0.05009041204671813, 'momentum': 0.8551367227388531}\n",
      "Best eval rmse: 0.7410722970962524\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparameter search using Hyperopt\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=8,\n",
    "        trials=trials,\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"loss\"])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
