{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "- Como trabalhar com Pipelines e o diferencial de termos eles em nossos projetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# load and split the data\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data\n",
    "                            , cancer.target \n",
    "                            , random_state=0)\n",
    "\n",
    "# compute minimum and maximum on the training data\n",
    "scaler = MinMaxScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# rescale the training data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "svm = SVC()\n",
    "# learn an SVM on the scaled training data\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# scale the test data and score the scaled data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Test score: {:.2f}\".format(svm.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo agora utilizando Pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"estimator\", SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()), (&#x27;SVM&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()), (&#x27;SVM&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()), ('SVM', SVC())])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Test score: {:.2f}\".format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV em pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'estimator__C': [0.1, 1, 10, 100],\n",
    "    'estimator__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'estimator__gamma': [0.1, 0.01, 0.001, 0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS' RESULTS\n",
      "Best cross-validation accuracy: 0.98\n",
      "Test set score: 0.96\n",
      "Best parameters: {'estimator__C': 10, 'estimator__gamma': 0.1, 'estimator__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"METRICS' RESULTS\")\n",
    "print(\"Best cross-validation accuracy: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de leaking (vazamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_selected.shape: (100, 500)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rnd = np.random.RandomState(seed=0)\n",
    "X = rnd.normal(size=(100, 10000))\n",
    "y = rnd.normal(size=(100,))\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "select = SelectPercentile(score_func=f_regression, percentile=5).fit(X, y)\n",
    "X_selected = select.transform(X)\n",
    "print(\"X_selected.shape: {}\".format(X_selected.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy (cv only on ridge): 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"Cross-validation accuracy (cv only on ridge): {:.2f}\".format(\n",
    "np.mean(cross_val_score(Ridge(), X_selected, y, cv=5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy (pipeline): -0.25\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"select\", SelectPercentile(score_func=f_regression,percentile=5)),\n",
    "    (\"ridge\", Ridge())\n",
    "])\n",
    "\n",
    "print(\"Cross-validation accuracy (pipeline): {:.2f}\".format(\n",
    "np.mean(cross_val_score(pipe, X, y, cv=5))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation with make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "make_pipe = make_pipeline(MinMaxScaler(),SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()), (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()), (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('minmaxscaler', MinMaxScaler()), ('svc', SVC())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acessando parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "275 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "                         ~~^~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "                                                ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.90142271        nan        nan        nan 0.72771546\n",
      " 0.94136799 0.9647606  0.94136799 0.94136799 0.94136799 0.94136799\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96248974        nan 0.61088919 0.95770178 0.97414501 0.97885089\n",
      "        nan 0.96473324        nan        nan        nan 0.96008208\n",
      " 0.97414501 0.97414501 0.97414501 0.97414501 0.97414501 0.97414501\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96248974        nan 0.61088919 0.95770178 0.97414501 0.97885089\n",
      "        nan 0.97414501        nan        nan        nan 0.96943912\n",
      " 0.97414501 0.97885089 0.97414501 0.97414501 0.97885089 0.97649795\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96248974        nan 0.61088919 0.95770178 0.97414501 0.97885089\n",
      "        nan 0.97184679        nan        nan        nan 0.97885089\n",
      " 0.97647059 0.97647059 0.97647059 0.97647059 0.97414501 0.97885089\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96248974        nan 0.61088919 0.95770178 0.97414501 0.97885089\n",
      "        nan 0.96243502        nan        nan        nan 0.97885089\n",
      " 0.96484268 0.96484268 0.96484268 0.96248974 0.97414501 0.97885089\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96248974        nan 0.61088919 0.95770178 0.97414501 0.97885089]\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;SScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;estimator&#x27;, LogisticRegression())]),\n",
       "             param_grid={&#x27;estimator__C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;estimator__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;estimator__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;,\n",
       "                                               &#x27;newton-cg&#x27;, &#x27;newton-cholesky&#x27;,\n",
       "                                               &#x27;sag&#x27;, &#x27;saga&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;SScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;estimator&#x27;, LogisticRegression())]),\n",
       "             param_grid={&#x27;estimator__C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;estimator__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;estimator__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;,\n",
       "                                               &#x27;newton-cg&#x27;, &#x27;newton-cholesky&#x27;,\n",
       "                                               &#x27;sag&#x27;, &#x27;saga&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;SScaler&#x27;, StandardScaler()),\n",
       "                (&#x27;estimator&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('SScaler', StandardScaler()),\n",
       "                                       ('estimator', LogisticRegression())]),\n",
       "             param_grid={'estimator__C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'estimator__penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'estimator__solver': ['lbfgs', 'liblinear',\n",
       "                                               'newton-cg', 'newton-cholesky',\n",
       "                                               'sag', 'saga']})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([('SScaler', StandardScaler()), ('estimator', LogisticRegression())])\n",
    "\n",
    "param_grid = {'estimator__C':[.01, .1, 1, 10, 100],\n",
    "              'estimator__solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "              'estimator__penalty':['l1','l2','elasticnet', None]\n",
    "              }\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                    random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "Pipeline(steps=[('SScaler', StandardScaler()),\n",
      "                ('estimator',\n",
      "                 LogisticRegression(C=0.01, penalty=None, solver='saga'))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;SScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;estimator&#x27;, LogisticRegression())]),\n",
       "             param_grid={&#x27;estimator__C&#x27;: [0.01, 0.1, 1, 10, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;SScaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;estimator&#x27;, LogisticRegression())]),\n",
       "             param_grid={&#x27;estimator__C&#x27;: [0.01, 0.1, 1, 10, 100]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;SScaler&#x27;, StandardScaler()),\n",
       "                (&#x27;estimator&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('SScaler', StandardScaler()),\n",
       "                                       ('estimator', LogisticRegression())]),\n",
       "             param_grid={'estimator__C': [0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([('SScaler', StandardScaler()), ('estimator', LogisticRegression())])\n",
    "\n",
    "param_grid = {'estimator__C':[.01, .1, 1, 10, 100]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
    "                                                    random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "Pipeline(steps=[('SScaler', StandardScaler()),\n",
      "                ('estimator', LogisticRegression(C=10))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "LogisticRegression(C=10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid.best_estimator_.named_steps[\"estimator\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression coefficients:\n",
      "[[ 0.01559634 -0.19828172  0.23505534 -0.27390037 -0.39359893  2.94062805\n",
      "  -1.31672318 -3.39000419  0.91262345 -1.02386013 -3.62153176  0.66292036\n",
      "  -0.10576852 -2.19282102 -0.30469832  0.10258468  0.37125806 -1.47505149\n",
      "   1.37682261  2.05968138 -1.73146187 -2.42802563  0.05138329 -1.93391932\n",
      "  -0.10341889  0.65348111 -2.35762942 -0.61404887 -2.71493656 -0.38967079]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression coefficients:\\n{}\".format(grid.best_estimator_.named_steps[\"estimator\"].coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data,\n",
    "                                                    diabetes.target\n",
    "                                                    , test_size=.2\n",
    "                                                    , random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('polynomialfeatures', PolynomialFeatures()),\n",
    "    ('estimator', Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'polynomialfeatures__degree': [1,2,3],\n",
    "    'estimator__alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;polynomialfeatures&#x27;,\n",
       "                                        PolynomialFeatures()),\n",
       "                                       (&#x27;estimator&#x27;, Ridge())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;estimator__alpha&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;polynomialfeatures__degree&#x27;: [1, 2, 3]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;polynomialfeatures&#x27;,\n",
       "                                        PolynomialFeatures()),\n",
       "                                       (&#x27;estimator&#x27;, Ridge())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;estimator__alpha&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;polynomialfeatures__degree&#x27;: [1, 2, 3]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;polynomialfeatures&#x27;, PolynomialFeatures()),\n",
       "                (&#x27;estimator&#x27;, Ridge())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('polynomialfeatures',\n",
       "                                        PolynomialFeatures()),\n",
       "                                       ('estimator', Ridge())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'estimator__alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'polynomialfeatures__degree': [1, 2, 3]})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(grid.cv_results_['mean_test_score'].reshape(3, -1),\n",
    "                vmin=0, cmap='viridis')\n",
    "plt.xlabel(\"Ridge__alpha\")\n",
    "plt.ylabel(\"polynomialfeatures__degree\")\n",
    "\n",
    "plt.xticks(\n",
    "             range(len(param_grid['estimator__alpha']))\n",
    "           , param_grid['estimator__alpha']\n",
    "    )\n",
    "plt.yticks(\n",
    "      range(len(param_grid['polynomialfeatures__degree']))\n",
    "    , param_grid['polynomialfeatures__degree']\n",
    ")\n",
    "\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'estimator__alpha': 10, 'polynomialfeatures__degree': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set score: 0.33\n"
     ]
    }
   ],
   "source": [
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without poly features: 0.33\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Score without poly features: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Which Model to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', StandardScaler()), ('classifier', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier': [SVC()], 'preprocessing': [StandardScaler(), None],\n",
    "    'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "\n",
    "    {'classifier': [RandomForestClassifier(n_estimators = 100)],\n",
    "     'preprocessing': [None], 'classifier__max_features':[1,2,3]   \n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'classifier': SVC(C=10, gamma=0.01), 'classifier__C': 10, 'classifier__gamma': 0.01, 'preprocessing': StandardScaler()}\n",
      "\n",
      "Best cross-validation score: 0.99\n",
      "Test-set score: 0.98\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=10)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
